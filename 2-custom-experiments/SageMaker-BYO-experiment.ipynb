{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYO container SageMaker Hyperparameter Search Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from sagemaker.session import s3_input\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "region = boto3.Session().region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'reinvent-409'\n",
    "repo_name = 'reinvent-409'\n",
    "image_tag = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment_run(job_name, hyperparams):\n",
    "    output_path = 's3://{}/'.format(bucket_name)\n",
    "    train_path = 's3://{}/cifar10-dataset/cifar-10-batches-py'.format(bucket_name)\n",
    "    eval_path = 's3://{}/cifar10-dataset/cifar-10-batches-py'.format(bucket_name)\n",
    "    image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, repo_name, image_tag)\n",
    "    \n",
    "    estimator = Estimator(\n",
    "        image_name=image,\n",
    "        role=role,\n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.p3.2xlarge',\n",
    "        output_path=output_path,\n",
    "        hyperparameters=hyperparams,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        metric_definitions=[{'Name': 'test_acc', 'Regex': 'test_acc:([0-9\\\\.]+)'}])\n",
    "\n",
    "    estimator.fit({'training': train_path, 'eval': eval_path}, wait=False, job_name=job_name)\n",
    "    return estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiment_set-small.json\", 'r') as stream:\n",
    "        experiment_param_set = json.load(stream)\n",
    "num_experiment_runs = len(experiment_param_set)\n",
    "print('Number of experiment runs: ', num_experiment_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'reinvent-aim409-' + time.strftime('%Y-%m-%d-%H-%M-%S-%j', time.gmtime()) + '-'\n",
    "max_parallel_jobs = 2\n",
    "jobs = {}\n",
    "job_names = []\n",
    "\n",
    "exp_batches = int(num_experiment_runs/max_parallel_jobs)\n",
    "exp_run_number = 0\n",
    "\n",
    "for i in range(exp_batches):\n",
    "    running_jobs = 0\n",
    "    running_job_names = []\n",
    "    for j in range(max_parallel_jobs):\n",
    "        time.sleep(2)\n",
    "        job = base_name + 'expbatch-' + str(i)+ 'job-' + str(j)\n",
    "        hps = experiment_param_set[exp_run_number]\n",
    "        jobs[job] = hps.copy()\n",
    "        running_job_names.append(job)\n",
    "        jname = train_experiment_run(job, hps)\n",
    "        job_names.append(jname)\n",
    "        running_jobs = running_jobs+1\n",
    "        exp_run_number = exp_run_number+1\n",
    "\n",
    "    while running_jobs > 0:\n",
    "        for job in running_job_names:\n",
    "            if client.describe_training_job(TrainingJobName=job)['TrainingJobStatus'] != 'InProgress':\n",
    "                running_jobs = running_jobs - 1\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = pd.DataFrame(columns=['job_name', 'batch_norm', 'batch_size', 'data_aug_cutout_size', 'epochs', 'max_learning_rate', 'momentum', 'test_acc'])\n",
    "for i in range(len(job_names)):\n",
    "    job_summary = client.describe_training_job(TrainingJobName=job_names[i])\n",
    "    accuracy = job_summary['FinalMetricDataList'][0]['Value']\n",
    "    hyp = pd.DataFrame.from_dict([job_summary['HyperParameters']])\n",
    "    hyp['test_acc'] = accuracy\n",
    "    hyp['job_name'] = job_names[i]\n",
    "    experiment_results = experiment_results.append(hyp,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
